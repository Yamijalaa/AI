{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yamijalaa/AI/blob/main/ChatGPT_with_your_files.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Requirement"
      ],
      "metadata": {
        "id": "0l3MD3312Itl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You might need to reinstall Pillow library if you receive PIL error\n",
        "# !pip uninstall Pillow\n",
        "# !pip install --upgrade Pillow\n",
        "# import PIL\n",
        "# print(PIL.__version__)"
      ],
      "metadata": {
        "id": "zxvS6Afa_RI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6WI5qfkUe0Q0"
      },
      "outputs": [],
      "source": [
        "!pip install openai -q\n",
        "!pip install langchain -q\n",
        "!pip install chromadb -q\n",
        "!pip install tiktoken -q\n",
        "!pip install pypdf -q\n",
        "!pip install unstructured[local-inference] -q\n",
        "!pip install gradio -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "TgkUctQX2Pbg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "aUTbnXkHe6Rv"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "llm = ChatOpenAI(temperature=0,model_name=\"gpt-4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Da3yPddNjxY"
      },
      "source": [
        "# Load your data into Reports folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSxialfUTh9b",
        "outputId": "e372ac9d-a094-461b-c232-d8b6288daca4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of documents: 5\n"
          ]
        }
      ],
      "source": [
        "from langchain.document_loaders import DirectoryLoader, WebBaseLoader\n",
        "\n",
        "pdf_loader = DirectoryLoader('/content/Reports/', glob=\"**/*.pdf\")\n",
        "txt_loader = DirectoryLoader('/content/Reports/', glob=\"**/*.txt\")\n",
        "word_loader = DirectoryLoader('/content/Reports/', glob=\"**/*.docx\")\n",
        "\n",
        "loaders = [pdf_loader, txt_loader, word_loader]\n",
        "local_documents = []\n",
        "for loader in loaders:\n",
        "    local_documents.extend(loader.load())\n",
        "\n",
        "# Define web links for online documents\n",
        "web_links = [\"https://www.ppgcoatingsservices.com/\",\n",
        "             \"https://www.ppgcoatingsservices.com/services/electrocoating\",\n",
        "             \"https://www.ppgcoatingsservices.com/services/powder-coating\",\n",
        "             \"https://www.ppgcoatingsservices.com/services/liquid-paint\"]\n",
        "\n",
        "# Load documents from web links\n",
        "web_loader = WebBaseLoader(web_links)\n",
        "web_documents = web_loader.load()\n",
        "\n",
        "# Combine local and web documents\n",
        "all_documents = local_documents + web_documents\n",
        "\n",
        "print(f\"Total number of documents: {len(all_documents)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34HYlsekNona"
      },
      "source": [
        "# Chunk the data, turn into Embeddings and save to VectorStore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "5aUybd6KhN7F",
        "outputId": "72b1347b-2b7f-44d4-c8c3-21de77fe2095",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.text_splitter:Created a chunk of size 2810, which is longer than the specified 2500\n"
          ]
        }
      ],
      "source": [
        "text_splitter = CharacterTextSplitter(chunk_size=2500, chunk_overlap=200)\n",
        "documents = text_splitter.split_documents(all_documents)\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "vectorstore = Chroma.from_documents(documents, embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ptdb1wVuNzom"
      },
      "source": [
        "# Calling the Langchain's QA chain with Chat History"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "tEBWBa1nhQwV"
      },
      "outputs": [],
      "source": [
        "qa = ConversationalRetrievalChain.from_llm(llm, vectorstore.as_retriever(), return_source_documents=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4okS40zMrLIL"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKmAxuY9rqxK"
      },
      "source": [
        "# Gradio Chat UI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "SAJVCq7Sly5Y",
        "outputId": "ab01f079-c909-4677-a6ec-7300173c5b39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7860, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User query: What materials can be powder coated?\n",
            "Chat history: []\n",
            "Updated chat history: [('What materials can be powder coated?', 'The materials that can be powder coated include:\\n\\n- Cold Rolled/Hot Rolled Steel\\n- Galvanized Steel\\n- Iron Castings\\n- Zinc Castings\\n- Copper/Brass\\n- Magnesium\\n- Aluminum Extrusions and Castings\\n- NiZn Plated Steel\\n- Stainless Steel\\n- Powder Metallurgy Parts\\n- Some Non-Metallics')]\n",
            "User query: Explain about pretreatment requirements\n",
            "Chat history: [['What materials can be powder coated?', 'The materials that can be powder coated include:\\n\\n- Cold Rolled/Hot Rolled Steel\\n- Galvanized Steel\\n- Iron Castings\\n- Zinc Castings\\n- Copper/Brass\\n- Magnesium\\n- Aluminum Extrusions and Castings\\n- NiZn Plated Steel\\n- Stainless Steel\\n- Powder Metallurgy Parts\\n- Some Non-Metallics']]\n",
            "Updated chat history: [['What materials can be powder coated?', 'The materials that can be powder coated include:\\n\\n- Cold Rolled/Hot Rolled Steel\\n- Galvanized Steel\\n- Iron Castings\\n- Zinc Castings\\n- Copper/Brass\\n- Magnesium\\n- Aluminum Extrusions and Castings\\n- NiZn Plated Steel\\n- Stainless Steel\\n- Powder Metallurgy Parts\\n- Some Non-Metallics'], ('Explain about pretreatment requirements', 'Selecting the proper pretreatment is essential to the success of powder coating. PPG Coatings Services offers multiple products and processes to meet most OEM specifications. These include zinc-phosphate, iron-phosphate, impellers and air blasters, chrome conversion coatings, and chrome and non-chrome sealers. These pretreatments help to prepare the surface of the material for the application of the powder coating.')]\n",
            "Keyboard interruption in main thread... closing server.\n"
          ]
        }
      ],
      "source": [
        "import gradio as gr\n",
        "# Define chat interface\n",
        "with gr.Blocks() as demo:\n",
        "    chatbot = gr.Chatbot()\n",
        "    msg = gr.Textbox()\n",
        "    clear = gr.Button(\"Clear\")\n",
        "    chat_history = []\n",
        "\n",
        "    def user(query, chat_history):\n",
        "        print(\"User query:\", query)\n",
        "        print(\"Chat history:\", chat_history)\n",
        "\n",
        "        # Convert chat history to list of tuples\n",
        "        chat_history_tuples = []\n",
        "        for message in chat_history:\n",
        "            chat_history_tuples.append((message[0], message[1]))\n",
        "\n",
        "        # Get result from QA chain\n",
        "        result = qa({\"question\": query, \"chat_history\": chat_history_tuples})\n",
        "\n",
        "        # Append user message and response to chat history\n",
        "        chat_history.append((query, result[\"answer\"]))\n",
        "        print(\"Updated chat history:\", chat_history)\n",
        "\n",
        "        return gr.update(value=\"\"), chat_history\n",
        "\n",
        "\n",
        "    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False)\n",
        "    clear.click(lambda: None, None, chatbot, queue=False)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(debug=True)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}